{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Purpose**: This notebook explores the self-driving vehicle dataset to understand:\n",
    "- What the data looks like\n",
    "- How many samples we have for each steering direction\n",
    "- Whether there are any problems with the data\n",
    "- How to split the data for training and testing\n",
    "\n",
    "**Why EDA is important**: Before building any machine learning model, we need to understand our data. This helps us:\n",
    "1. Choose the right models\n",
    "2. Avoid common mistakes\n",
    "3. Explain why our models work or fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Import Libraries\n",
    "\n",
    "**What are libraries?** Pre-written code that helps us do common tasks.\n",
    "\n",
    "- `numpy`: Math operations on arrays (lists of numbers)\n",
    "- `matplotlib`: Draw plots and charts\n",
    "- `seaborn`: Make prettier charts\n",
    "- `sklearn`: Machine learning tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: # Show plots inside the notebook\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np                          # For working with arrays of numbers\n",
    "import matplotlib.pyplot as plt             # For creating plots\n",
    "import seaborn as sns                       # For creating nice-looking plots\n",
    "from sklearn.decomposition import PCA       # For reducing dimensions (explained later)\n",
    "from collections import Counter             # For counting things\n",
    "\n",
    "# Settings to make plots look better\n",
    "plt.style.use('default')                    # Use default plot style\n",
    "sns.set_palette(\"husl\")                     # Use colorful palette\n",
    "%matplotlib inline\n",
    "# Show plots inside the notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Dataset\n",
    "\n",
    "**What is our dataset?** A `.npy` file containing:\n",
    "- Images: 64\u00d764 grayscale pictures from the vehicle camera\n",
    "- Labels: Steering direction (-1 = left, 0 = forward, 1 = right)\n",
    "\n",
    "**Why .npy format?** It's a NumPy file format that stores arrays efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# np.load() reads a .npy file\n",
    "# allow_pickle=True lets us load this specific file format\n",
    "data = np.load('../data/training_data-SIZE10000-TIME80557.npy', allow_pickle=True)\n",
    "\n",
    "# Print basic information\n",
    "print(f\"Total number of samples: {len(data)}\")\n",
    "print(f\"Type of data: {type(data)}\")\n",
    "print(f\"First sample structure: image shape = {data[0][0].shape}, label = {data[0][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Separate Images (X) and Labels (y)\n",
    "\n",
    "**Convention in machine learning**:\n",
    "- `X` = features (input data) = images\n",
    "- `y` = labels (what we want to predict) = steering directions\n",
    "\n",
    "**Why separate them?** Most machine learning functions expect X and y as separate inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract images (X) and labels (y)\n",
    "# sample[0] = image, sample[1] = label\n",
    "X = np.array([sample[0] for sample in data])  # All images\n",
    "y = np.array([sample[1] for sample in data])  # All labels\n",
    "\n",
    "print(f\"X shape: {X.shape}\")  # Should be (9900, 64, 64)\n",
    "print(f\"y shape: {y.shape}\")  # Should be (9900,)\n",
    "print(f\"Unique labels: {np.unique(y)}\")  # Should be [-1, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Class Distribution\n",
    "\n",
    "**Purpose**: Count how many samples we have for each steering direction.\n",
    "\n",
    "**Why this matters**: If we have many more \"forward\" samples than \"left\" or \"right\", the model might:\n",
    "- Always predict \"forward\" (lazy strategy)\n",
    "- Perform poorly on turns\n",
    "\n",
    "This is called **class imbalance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count samples for each class\n",
    "class_counts = Counter(y)  # Counter counts occurrences\n",
    "\n",
    "# Create a readable summary\n",
    "label_names = {-1: 'Left', 0: 'Forward', 1: 'Right'}\n",
    "total = len(y)\n",
    "\n",
    "print(\"Class Distribution:\")\n",
    "print(\"-\" * 50)\n",
    "for label in [-1, 0, 1]:\n",
    "    count = class_counts[label]\n",
    "    percentage = (count / total) * 100\n",
    "    print(f\"{label_names[label]:8s} (label={label:2d}): {count:5d} samples ({percentage:5.1f}%)\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Total: {total} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution with bar chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart\n",
    "labels = ['Left', 'Forward', 'Right']\n",
    "counts = [class_counts[-1], class_counts[0], class_counts[1]]\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "axes[0].bar(labels, counts, color=colors)\n",
    "axes[0].set_ylabel('Number of Samples', fontsize=12)\n",
    "axes[0].set_title('Class Distribution (Counts)', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, (label, count) in enumerate(zip(labels, counts)):\n",
    "    axes[0].text(i, count + 100, str(count), ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(counts, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "axes[1].set_title('Class Distribution (Percentages)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Key observation\n",
    "print(\"\\n\u26a0\ufe0f KEY OBSERVATION:\")\n",
    "print(f\"Forward class has {class_counts[0] / class_counts[1]:.1f}x more samples than Right class!\")\n",
    "print(\"This severe imbalance will likely cause the model to bias toward 'Forward' predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Sample Images\n",
    "\n",
    "**Purpose**: Look at actual images to understand:\n",
    "- What does the camera see?\n",
    "- Do different steering directions look visually different?\n",
    "- Are labels correct?\n",
    "\n",
    "**What to look for**:\n",
    "- Track surface (light gray)\n",
    "- Track edges (black)\n",
    "- Vehicle position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 5 random samples from each class\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "\n",
    "# For each class\n",
    "for row, label in enumerate([-1, 0, 1]):\n",
    "    # Find indices where y equals this label\n",
    "    indices = np.where(y == label)[0]  # np.where finds matching positions\n",
    "    \n",
    "    # Randomly select 5 samples\n",
    "    selected = np.random.choice(indices, size=5, replace=False)\n",
    "    \n",
    "    # Display each sample\n",
    "    for col, idx in enumerate(selected):\n",
    "        axes[row, col].imshow(X[idx], cmap='gray')  # cmap='gray' shows grayscale\n",
    "        axes[row, col].axis('off')  # Hide axis numbers\n",
    "        \n",
    "        # Add title to first column only\n",
    "        if col == 0:\n",
    "            axes[row, col].set_ylabel(label_names[label], fontsize=14, fontweight='bold')\n",
    "\n",
    "fig.suptitle('Random Samples from Each Class', fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Label Quality Analysis\n",
    "\n",
    "**Important discovery**: Some images don't match their labels!\n",
    "\n",
    "**Why does this happen?**\n",
    "- Labels are **reactive steering commands**, not descriptions of what the image shows\n",
    "- Example: Image shows vehicle drifting right \u2192 Label = \"turn left\" (to correct)\n",
    "- This is called **temporal lag** - the action responds to the current state\n",
    "\n",
    "**What this means for our project**:\n",
    "- Single-frame prediction is inherently difficult\n",
    "- Sequential models (using multiple frames) should work better\n",
    "- We shouldn't expect 90%+ accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually examine some examples that might look confusing\n",
    "# Let's look at left turn examples from the middle of the dataset\n",
    "left_indices = np.where(y == -1)[0]\n",
    "sample_indices = left_indices[20:25]  # Pick a few examples\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    axes[i].imshow(X[idx], cmap='gray')\n",
    "    axes[i].set_title(f\"Label: {label_names[y[idx]]}\\nIndex: {idx}\", fontsize=10)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Example: Left Turn Labels (Notice some might not visually show left turns)', \n",
    "             fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\ud83d\udca1 INSIGHT:\")\n",
    "print(\"If you see images labeled 'left' that don't look like they need to turn left,\")\n",
    "print(\"this is expected! The label is the CORRECTIVE ACTION, not a description of the image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pixel Statistics\n",
    "\n",
    "**Purpose**: Analyze pixel intensities to understand:\n",
    "- Are different classes visually distinct?\n",
    "- What does an \"average\" left/forward/right image look like?\n",
    "\n",
    "**Pixel values**:\n",
    "- Range from 0 (black) to 255 (white)\n",
    "- Track surface: light gray (high values)\n",
    "- Track edges: black (low values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean (average) image for each class\n",
    "# Mean image = average all pixels across all images of that class\n",
    "mean_images = {}\n",
    "for label in [-1, 0, 1]:\n",
    "    # Get all images with this label\n",
    "    class_images = X[y == label]\n",
    "    # Calculate mean across all images (axis=0 means \"across samples\")\n",
    "    mean_images[label] = np.mean(class_images, axis=0)\n",
    "\n",
    "# Display mean images\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for i, label in enumerate([-1, 0, 1]):\n",
    "    axes[i].imshow(mean_images[label], cmap='gray')\n",
    "    axes[i].set_title(f'Mean {label_names[label]} Image', fontsize=12, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Average Image for Each Class', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\u2753 QUESTION TO THINK ABOUT:\")\n",
    "print(\"Do the mean images look different from each other?\")\n",
    "print(\"If they look very similar, it means the classes are hard to distinguish visually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pixel intensity distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, label in enumerate([-1, 0, 1]):\n",
    "    # Get all images with this label and flatten them\n",
    "    # flatten() converts 64x64 image to 4096 values in a list\n",
    "    class_images = X[y == label]\n",
    "    all_pixels = class_images.flatten()  # Combine all pixels from all images\n",
    "    \n",
    "    # Create histogram (count how many pixels have each value)\n",
    "    axes[i].hist(all_pixels, bins=50, color=['#FF6B6B', '#4ECDC4', '#45B7D1'][i], alpha=0.7)\n",
    "    axes[i].set_xlabel('Pixel Intensity (0=black, 255=white)', fontsize=10)\n",
    "    axes[i].set_ylabel('Frequency (count)', fontsize=10)\n",
    "    axes[i].set_title(f'{label_names[label]} Pixel Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[i].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\ud83d\udca1 INTERPRETATION:\")\n",
    "print(\"If all three histograms look similar, the classes are not easily separable by pixel values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Temporal Analysis (Very Important!)\n",
    "\n",
    "**What is temporal correlation?**\n",
    "- Our data is a video sequence (consecutive frames)\n",
    "- Nearby frames look very similar (the vehicle doesn't teleport!)\n",
    "- Correlation = how similar two frames are (1.0 = identical, 0.0 = completely different)\n",
    "\n",
    "**Why this matters**:\n",
    "- If we do random train/test split, test images might be very similar to training images\n",
    "- Model might \"cheat\" by memorizing, not actually learning\n",
    "- We need **temporal split** instead: train on first part, test on last part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between consecutive frames\n",
    "# Correlation measures how similar two images are\n",
    "correlations = []\n",
    "\n",
    "# Compare each frame with the next frame\n",
    "for i in range(len(X) - 1):\n",
    "    # Flatten images to 1D arrays\n",
    "    img1 = X[i].flatten()\n",
    "    img2 = X[i+1].flatten()\n",
    "    \n",
    "    # Calculate correlation coefficient\n",
    "    # np.corrcoef returns a 2x2 matrix, we want the off-diagonal value\n",
    "    corr = np.corrcoef(img1, img2)[0, 1]\n",
    "    correlations.append(corr)\n",
    "\n",
    "# Plot correlation over time\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(correlations, alpha=0.5, linewidth=0.5)\n",
    "plt.axhline(y=0.8, color='r', linestyle='--', label='High correlation threshold (0.8)')\n",
    "plt.axhline(y=0.5, color='orange', linestyle='--', label='Medium correlation threshold (0.5)')\n",
    "plt.xlabel('Frame Index', fontsize=12)\n",
    "plt.ylabel('Correlation with Next Frame', fontsize=12)\n",
    "plt.title('Temporal Correlation: How Similar Are Consecutive Frames?', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "print(f\"Mean correlation: {np.mean(correlations):.3f}\")\n",
    "print(f\"Median correlation: {np.median(correlations):.3f}\")\n",
    "print(f\"Percentage of frames with correlation > 0.8: {(np.array(correlations) > 0.8).mean() * 100:.1f}%\")\n",
    "\n",
    "print(\"\\n\u26a0\ufe0f KEY FINDING:\")\n",
    "if np.mean(correlations) > 0.7:\n",
    "    print(\"Consecutive frames are HIGHLY correlated!\")\n",
    "    print(\"\u2192 Random train/test split will leak information\")\n",
    "    print(\"\u2192 Must use temporal split instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze correlation at different time gaps\n",
    "# Does correlation decrease as frames get further apart?\n",
    "gaps = [1, 5, 10, 20, 50, 100]\n",
    "gap_correlations = []\n",
    "\n",
    "for gap in gaps:\n",
    "    corrs = []\n",
    "    for i in range(len(X) - gap):\n",
    "        img1 = X[i].flatten()\n",
    "        img2 = X[i + gap].flatten()\n",
    "        corr = np.corrcoef(img1, img2)[0, 1]\n",
    "        corrs.append(corr)\n",
    "    gap_correlations.append(np.mean(corrs))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(gaps, gap_correlations, marker='o', linewidth=2, markersize=8)\n",
    "plt.xlabel('Frame Gap (how many frames apart)', fontsize=12)\n",
    "plt.ylabel('Average Correlation', fontsize=12)\n",
    "plt.title('How Does Correlation Decay with Time?', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find when correlation drops below 0.5\n",
    "for gap, corr in zip(gaps, gap_correlations):\n",
    "    print(f\"Gap = {gap:3d} frames: correlation = {corr:.3f}\")\n",
    "\n",
    "print(\"\\n\ud83d\udca1 INSIGHT:\")\n",
    "print(\"Frames need to be at least X frames apart to be considered 'independent'.\")\n",
    "print(\"This tells us how carefully we need to split our data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Label Transition Analysis\n",
    "\n",
    "**Purpose**: Understand the sequence of steering decisions.\n",
    "\n",
    "**Questions**:\n",
    "- After a left turn, what usually comes next?\n",
    "- Do we see realistic sequences? (e.g., left \u2192 forward \u2192 right on a curve)\n",
    "- Are there impossible transitions? (e.g., always left \u2192 left)\n",
    "\n",
    "**Transition matrix**: A table showing \"if current label is X, next label is Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build transition matrix\n",
    "# transition[i, j] = count of times label i is followed by label j\n",
    "transition_matrix = np.zeros((3, 3))\n",
    "\n",
    "for i in range(len(y) - 1):\n",
    "    current_label = y[i]\n",
    "    next_label = y[i + 1]\n",
    "    # Map labels: -1\u21920, 0\u21921, 1\u21922 for indexing\n",
    "    transition_matrix[current_label + 1, next_label + 1] += 1\n",
    "\n",
    "# Normalize to probabilities (each row sums to 1)\n",
    "transition_probs = transition_matrix / transition_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Visualize as heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(transition_probs, annot=True, fmt='.2f', cmap='YlOrRd',\n",
    "            xticklabels=['Left', 'Forward', 'Right'],\n",
    "            yticklabels=['Left', 'Forward', 'Right'],\n",
    "            cbar_kws={'label': 'Probability'})\n",
    "plt.xlabel('Next Label', fontsize=12)\n",
    "plt.ylabel('Current Label', fontsize=12)\n",
    "plt.title('Label Transition Probabilities\\n(What label usually follows what?)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\ud83d\udcca INTERPRETATION GUIDE:\")\n",
    "print(\"Each row shows: if current label is X, what's the probability next label is Y?\")\n",
    "print(\"Example: If current=Forward, what's P(next=Forward)?\")\n",
    "print(f\"\u2192 P(Forward \u2192 Forward) = {transition_probs[1, 1]:.2f}\")\n",
    "print(\"\\nHigh diagonal values = labels tend to repeat (vehicle keeps same direction)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Dimensionality Reduction (PCA)\n",
    "\n",
    "**What is PCA (Principal Component Analysis)?**\n",
    "- Each image has 64\u00d764 = 4,096 pixels (dimensions)\n",
    "- PCA finds the 2 most important directions (principal components)\n",
    "- We can plot data in 2D to see if classes are separable\n",
    "\n",
    "**Why 2D?** So we can visualize it!\n",
    "\n",
    "**What to look for**:\n",
    "- Do different colors (classes) form separate clusters?\n",
    "- If yes: classes are easily separable \u2192 model should work well\n",
    "- If no: classes overlap \u2192 harder problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for PCA\n",
    "# PCA needs data as (samples, features)\n",
    "# Our images are (9900, 64, 64), we need (9900, 4096)\n",
    "X_flat = X.reshape(len(X), -1)  # -1 means \"calculate this dimension automatically\"\n",
    "\n",
    "print(f\"Original shape: {X.shape}\")\n",
    "print(f\"Flattened shape: {X_flat.shape}\")\n",
    "print(f\"Reduced from {X.shape[1]}\u00d7{X.shape[2]} = {X.shape[1]*X.shape[2]} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to reduce to 2 dimensions\n",
    "pca = PCA(n_components=2)  # Keep only 2 components\n",
    "X_2d = pca.fit_transform(X_flat)  # Transform data to 2D\n",
    "\n",
    "print(f\"Reduced to: {X_2d.shape}\")\n",
    "print(f\"\\nVariance explained by 2 components: {pca.explained_variance_ratio_.sum():.1%}\")\n",
    "print(\"(This tells us how much information we kept)\")\n",
    "print(f\"Component 1 explains: {pca.explained_variance_ratio_[0]:.1%}\")\n",
    "print(f\"Component 2 explains: {pca.explained_variance_ratio_[1]:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot in 2D space\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot each class with different color\n",
    "colors = {-1: '#FF6B6B', 0: '#4ECDC4', 1: '#45B7D1'}\n",
    "for label in [-1, 0, 1]:\n",
    "    # Get points for this class\n",
    "    mask = (y == label)  # Boolean array: True where y equals label\n",
    "    plt.scatter(X_2d[mask, 0], X_2d[mask, 1], \n",
    "                c=colors[label], label=label_names[label],\n",
    "                alpha=0.6, s=20, edgecolors='none')\n",
    "\n",
    "plt.xlabel(f'First Principal Component ({pca.explained_variance_ratio_[0]:.1%} variance)', fontsize=12)\n",
    "plt.ylabel(f'Second Principal Component ({pca.explained_variance_ratio_[1]:.1%} variance)', fontsize=12)\n",
    "plt.title('2D PCA Projection: Are Classes Separable?', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=12, markerscale=2)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u2753 QUESTION:\")\n",
    "print(\"Do you see three separate clusters?\")\n",
    "print(\"- YES \u2192 Classes are linearly separable, simple models might work well\")\n",
    "print(\"- NO \u2192 Classes overlap, need more complex models (like neural networks)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Train/Validation/Test Splits\n",
    "\n",
    "**Why split data?**\n",
    "- **Train set**: Model learns from this\n",
    "- **Validation set**: Tune hyperparameters (like learning rate)\n",
    "- **Test set**: Final evaluation (model has never seen this)\n",
    "\n",
    "**Two splitting strategies**:\n",
    "\n",
    "### Strategy A: Random Split (Naive)\n",
    "- Randomly shuffle and split\n",
    "- Problem: Consecutive frames are similar, test set might \"leak\" into train set\n",
    "\n",
    "### Strategy B: Temporal Split (Proper)\n",
    "- First 70% \u2192 train\n",
    "- Next 15% \u2192 validation  \n",
    "- Last 15% \u2192 test\n",
    "- Advantage: Test set is truly unseen (future data)\n",
    "\n",
    "**We'll create both and compare results later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy A: Random Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split: 70% train, 30% temp\n",
    "X_train_rand, X_temp, y_train_rand, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "# stratify=y ensures each split has similar class distribution\n",
    "\n",
    "# Second split: split temp into 50% validation, 50% test\n",
    "X_val_rand, X_test_rand, y_val_rand, y_test_rand = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Random Split:\")\n",
    "print(f\"Train: {len(X_train_rand)} samples\")\n",
    "print(f\"Val:   {len(X_val_rand)} samples\")\n",
    "print(f\"Test:  {len(X_test_rand)} samples\")\n",
    "print(f\"Total: {len(X_train_rand) + len(X_val_rand) + len(X_test_rand)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy B: Temporal Split\n",
    "n = len(X)\n",
    "train_end = int(0.7 * n)      # 70% for training\n",
    "val_end = int(0.85 * n)       # Next 15% for validation\n",
    "# Remaining 15% for test\n",
    "\n",
    "X_train_temp = X[:train_end]\n",
    "y_train_temp = y[:train_end]\n",
    "\n",
    "X_val_temp = X[train_end:val_end]\n",
    "y_val_temp = y[train_end:val_end]\n",
    "\n",
    "X_test_temp = X[val_end:]\n",
    "y_test_temp = y[val_end:]\n",
    "\n",
    "print(\"\\nTemporal Split:\")\n",
    "print(f\"Train: {len(X_train_temp)} samples (frames 0 to {train_end-1})\")\n",
    "print(f\"Val:   {len(X_val_temp)} samples (frames {train_end} to {val_end-1})\")\n",
    "print(f\"Test:  {len(X_test_temp)} samples (frames {val_end} to {n-1})\")\n",
    "print(f\"Total: {len(X_train_temp) + len(X_val_temp) + len(X_test_temp)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare class distributions in both strategies\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Random split distributions\n",
    "for i, (y_split, title) in enumerate([\n",
    "    (y_train_rand, 'Random: Train'),\n",
    "    (y_val_rand, 'Random: Val'),\n",
    "    (y_test_rand, 'Random: Test')\n",
    "]):\n",
    "    counts = [np.sum(y_split == -1), np.sum(y_split == 0), np.sum(y_split == 1)]\n",
    "    axes[0, i].bar(['Left', 'Forward', 'Right'], counts, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "    axes[0, i].set_title(title, fontsize=12, fontweight='bold')\n",
    "    axes[0, i].set_ylabel('Count')\n",
    "    \n",
    "# Temporal split distributions\n",
    "for i, (y_split, title) in enumerate([\n",
    "    (y_train_temp, 'Temporal: Train'),\n",
    "    (y_val_temp, 'Temporal: Val'),\n",
    "    (y_test_temp, 'Temporal: Test')\n",
    "]):\n",
    "    counts = [np.sum(y_split == -1), np.sum(y_split == 0), np.sum(y_split == 1)]\n",
    "    axes[1, i].bar(['Left', 'Forward', 'Right'], counts, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "    axes[1, i].set_title(title, fontsize=12, fontweight='bold')\n",
    "    axes[1, i].set_ylabel('Count')\n",
    "\n",
    "plt.suptitle('Class Distribution in Different Splits', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca OBSERVATION:\")\n",
    "print(\"Random split: All three sets have similar proportions (because of stratify=y)\")\n",
    "print(\"Temporal split: Proportions might differ (depends on where in the track we split)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Splits for Later Use\n",
    "\n",
    "**Purpose**: Save our train/val/test splits so:\n",
    "- We use the same splits in all experiments (fair comparison)\n",
    "- Other team members can use the same splits\n",
    "\n",
    "**File format**: `.npz` = compressed NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save random splits\n",
    "np.savez('../data/splits_random.npz',\n",
    "         X_train=X_train_rand, y_train=y_train_rand,\n",
    "         X_val=X_val_rand, y_val=y_val_rand,\n",
    "         X_test=X_test_rand, y_test=y_test_rand)\n",
    "\n",
    "# Save temporal splits\n",
    "np.savez('../data/splits_temporal.npz',\n",
    "         X_train=X_train_temp, y_train=y_train_temp,\n",
    "         X_val=X_val_temp, y_val=y_val_temp,\n",
    "         X_test=X_test_temp, y_test=y_test_temp)\n",
    "\n",
    "print(\"\u2705 Splits saved successfully!\")\n",
    "print(\"Files created:\")\n",
    "print(\"  - data/splits_random.npz\")\n",
    "print(\"  - data/splits_temporal.npz\")\n",
    "print(\"\\nTo load later: data = np.load('data/splits_random.npz')\")\n",
    "print(\"Then access: data['X_train'], data['y_train'], etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary of Key Findings\n",
    "\n",
    "**Based on our exploratory data analysis, here are the main findings:**\n",
    "\n",
    "### 1. Severe Class Imbalance \u26a0\ufe0f\n",
    "- Forward: 74.2% (dominant class)\n",
    "- Left: 16.4%\n",
    "- Right: 9.5% (minority class)\n",
    "\n",
    "**Implication**: Models will likely bias toward predicting \"Forward\". Need to address with:\n",
    "- Class weights in loss function\n",
    "- Oversampling minority classes (SMOTE)\n",
    "- Evaluation metrics beyond accuracy (F1-score per class)\n",
    "\n",
    "### 2. High Temporal Correlation \ud83d\udcc8\n",
    "- Consecutive frames are highly correlated (>0.7)\n",
    "- Frames within ~10 steps are almost identical\n",
    "\n",
    "**Implication**: \n",
    "- Random train/test split is inappropriate (data leakage)\n",
    "- Must use temporal split for realistic evaluation\n",
    "- Sequential models (LSTM, temporal CNN) should outperform single-frame models\n",
    "\n",
    "### 3. Label Noise (Temporal Lag) \ud83d\udd04\n",
    "- Labels are reactive control signals, not image descriptions\n",
    "- Many images visually contradict their labels\n",
    "\n",
    "**Implication**:\n",
    "- Inherent difficulty in single-frame prediction\n",
    "- Don't expect >80-90% accuracy\n",
    "- Temporal context is crucial\n",
    "\n",
    "### 4. Limited Visual Separability \ud83d\udc41\ufe0f\n",
    "- PCA shows significant class overlap\n",
    "- Mean images look similar across classes\n",
    "\n",
    "**Implication**:\n",
    "- Linear models may struggle\n",
    "- Need non-linear models (neural networks)\n",
    "- Feature engineering might help\n",
    "\n",
    "### 5. Small Dataset \ud83d\udcca\n",
    "- Only 9,900 samples total\n",
    "- Right class has only 937 samples\n",
    "\n",
    "**Implication**:\n",
    "- Deep CNNs may overfit\n",
    "- Need regularization (dropout, weight decay)\n",
    "- Data augmentation might help\n",
    "- Simpler models might outperform complex ones\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Baseline Models** (Notebook 02):\n",
    "   - Majority class classifier\n",
    "   - Logistic Regression\n",
    "   - Random Forest\n",
    "\n",
    "2. **CNN Models** (Notebook 03):\n",
    "   - Simple CNN (2-3 layers)\n",
    "   - Deeper architectures\n",
    "   - Compare random vs temporal splits\n",
    "\n",
    "3. **Advanced Methods** (Notebook 04):\n",
    "   - LSTM for temporal sequences\n",
    "   - 1D-CNN on frame sequences\n",
    "   - Ensemble methods\n",
    "\n",
    "4. **Analysis** (Notebook 05):\n",
    "   - Error analysis\n",
    "   - Confusion matrices\n",
    "   - Statistical significance testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}