{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Logistic Regression for Steering Classification\n",
        "\n",
        "This notebook trains and evaluates Logistic Regression models on the steering image dataset:\n",
        "- **Standard Logistic Regression** (no regularization)\n",
        "- **L1 Regularized (Lasso)** - promotes sparsity, feature selection\n",
        "- **L2 Regularized (Ridge)** - shrinks coefficients, prevents overfitting\n",
        "\n",
        "We train each variant using both:\n",
        "1. Raw vectorized image data (with PCA for dimensionality reduction)\n",
        "2. Engineered features (38 domain-specific features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import shared utilities\n",
        "from utils import (\n",
        "    load_data, preprocess_data, evaluate_model, \n",
        "    cross_validate_model, save_results, get_class_weights,\n",
        "    print_class_distribution, CLASSES, RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(\"Libraries loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load both raw and engineered features\n",
        "data = load_data()\n",
        "\n",
        "X_raw, y_raw = data['raw']\n",
        "X_eng, y_eng, feature_names = data['engineered']\n",
        "\n",
        "print(f\"\\nRaw features shape: {X_raw.shape}\")\n",
        "print(f\"Engineered features shape: {X_eng.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preprocess Data\n",
        "\n",
        "- Apply PCA to raw data (4096 â†’ ~50 features) to handle multicollinearity\n",
        "- Standardize all features\n",
        "- Stratified train/test split (80/20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess raw data with PCA\n",
        "print(\"Preprocessing RAW data with PCA:\")\n",
        "raw_processed = preprocess_data(\n",
        "    X_raw, y_raw, \n",
        "    test_size=0.2, \n",
        "    apply_pca_reduction=True, \n",
        "    pca_variance=0.95,\n",
        "    scale=True\n",
        ")\n",
        "\n",
        "print(\"\\nPreprocessing ENGINEERED data:\")\n",
        "eng_processed = preprocess_data(\n",
        "    X_eng, y_eng, \n",
        "    test_size=0.2, \n",
        "    apply_pca_reduction=False,\n",
        "    scale=True\n",
        ")\n",
        "\n",
        "# Check class distribution in training set\n",
        "print(\"\\nTraining set class distribution:\")\n",
        "print_class_distribution(raw_processed['y_train'], raw_processed['label_encoder'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Standard Logistic Regression (No Regularization)\n",
        "\n",
        "Using very high C value (low regularization) to approximate unregularized logistic regression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get class weights to handle imbalance\n",
        "class_weights = get_class_weights()\n",
        "print(\"Class weights:\", class_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard Logistic Regression - Raw (PCA) Features\n",
        "print(\"Training Standard Logistic Regression on RAW (PCA) features...\")\n",
        "\n",
        "lr_standard_raw = LogisticRegression(\n",
        "    C=1e6,  # Very high C = minimal regularization\n",
        "    max_iter=1000,\n",
        "    class_weight='balanced',\n",
        "    random_state=RANDOM_STATE,\n",
        "    solver='lbfgs',\n",
        "    multi_class='multinomial'\n",
        ")\n",
        "\n",
        "lr_standard_raw.fit(raw_processed['X_train'], raw_processed['y_train'])\n",
        "\n",
        "results_standard_raw = evaluate_model(\n",
        "    lr_standard_raw,\n",
        "    raw_processed['X_test'],\n",
        "    raw_processed['y_test'],\n",
        "    model_name='Logistic Regression (Standard)',\n",
        "    feature_type='raw',\n",
        "    label_encoder=raw_processed['label_encoder']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard Logistic Regression - Engineered Features\n",
        "print(\"Training Standard Logistic Regression on ENGINEERED features...\")\n",
        "\n",
        "lr_standard_eng = LogisticRegression(\n",
        "    C=1e6,\n",
        "    max_iter=1000,\n",
        "    class_weight='balanced',\n",
        "    random_state=RANDOM_STATE,\n",
        "    solver='lbfgs',\n",
        "    multi_class='multinomial'\n",
        ")\n",
        "\n",
        "lr_standard_eng.fit(eng_processed['X_train'], eng_processed['y_train'])\n",
        "\n",
        "results_standard_eng = evaluate_model(\n",
        "    lr_standard_eng,\n",
        "    eng_processed['X_test'],\n",
        "    eng_processed['y_test'],\n",
        "    model_name='Logistic Regression (Standard)',\n",
        "    feature_type='engineered',\n",
        "    label_encoder=eng_processed['label_encoder']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. L1 Regularized Logistic Regression (Lasso)\n",
        "\n",
        "L1 regularization promotes sparsity - can shrink coefficients to exactly zero, performing feature selection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# L1 Logistic Regression with Cross-Validation for C - Raw Features\n",
        "print(\"Training L1 Logistic Regression on RAW (PCA) features with CV...\")\n",
        "\n",
        "# Use LogisticRegressionCV for automatic C selection\n",
        "lr_l1_raw = LogisticRegressionCV(\n",
        "    penalty='l1',\n",
        "    Cs=10,  # 10 values of C to try\n",
        "    cv=5,\n",
        "    scoring='f1_macro',\n",
        "    solver='saga',\n",
        "    max_iter=2000,\n",
        "    class_weight='balanced',\n",
        "    random_state=RANDOM_STATE,\n",
        "    multi_class='multinomial',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lr_l1_raw.fit(raw_processed['X_train'], raw_processed['y_train'])\n",
        "\n",
        "print(f\"Best C: {lr_l1_raw.C_[0]:.4f}\")\n",
        "\n",
        "results_l1_raw = evaluate_model(\n",
        "    lr_l1_raw,\n",
        "    raw_processed['X_test'],\n",
        "    raw_processed['y_test'],\n",
        "    model_name='Logistic Regression (L1/Lasso)',\n",
        "    feature_type='raw',\n",
        "    label_encoder=raw_processed['label_encoder']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# L1 Logistic Regression - Engineered Features\n",
        "print(\"Training L1 Logistic Regression on ENGINEERED features with CV...\")\n",
        "\n",
        "lr_l1_eng = LogisticRegressionCV(\n",
        "    penalty='l1',\n",
        "    Cs=10,\n",
        "    cv=5,\n",
        "    scoring='f1_macro',\n",
        "    solver='saga',\n",
        "    max_iter=2000,\n",
        "    class_weight='balanced',\n",
        "    random_state=RANDOM_STATE,\n",
        "    multi_class='multinomial',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lr_l1_eng.fit(eng_processed['X_train'], eng_processed['y_train'])\n",
        "\n",
        "print(f\"Best C: {lr_l1_eng.C_[0]:.4f}\")\n",
        "\n",
        "results_l1_eng = evaluate_model(\n",
        "    lr_l1_eng,\n",
        "    eng_processed['X_test'],\n",
        "    eng_processed['y_test'],\n",
        "    model_name='Logistic Regression (L1/Lasso)',\n",
        "    feature_type='engineered',\n",
        "    label_encoder=eng_processed['label_encoder']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze L1 feature selection on engineered features\n",
        "print(\"\\nL1 Feature Selection (Engineered Features):\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Get coefficients\n",
        "coefs = lr_l1_eng.coef_\n",
        "\n",
        "# Count non-zero coefficients per class\n",
        "for i, cls in enumerate(CLASSES):\n",
        "    n_nonzero = np.sum(coefs[i] != 0)\n",
        "    print(f\"{cls}: {n_nonzero}/{len(feature_names)} features selected\")\n",
        "\n",
        "# Find most important features (by max absolute coefficient across classes)\n",
        "max_coefs = np.max(np.abs(coefs), axis=0)\n",
        "top_indices = np.argsort(max_coefs)[::-1][:10]\n",
        "\n",
        "print(\"\\nTop 10 Features by L1 Coefficient Magnitude:\")\n",
        "for idx in top_indices:\n",
        "    print(f\"  {feature_names[idx]}: {max_coefs[idx]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. L2 Regularized Logistic Regression (Ridge)\n",
        "\n",
        "L2 regularization shrinks coefficients toward zero but never exactly to zero. Generally better for prediction when many features are relevant.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# L2 Logistic Regression with Cross-Validation for C - Raw Features\n",
        "print(\"Training L2 Logistic Regression on RAW (PCA) features with CV...\")\n",
        "\n",
        "lr_l2_raw = LogisticRegressionCV(\n",
        "    penalty='l2',\n",
        "    Cs=10,\n",
        "    cv=5,\n",
        "    scoring='f1_macro',\n",
        "    solver='lbfgs',\n",
        "    max_iter=1000,\n",
        "    class_weight='balanced',\n",
        "    random_state=RANDOM_STATE,\n",
        "    multi_class='multinomial',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lr_l2_raw.fit(raw_processed['X_train'], raw_processed['y_train'])\n",
        "\n",
        "print(f\"Best C: {lr_l2_raw.C_[0]:.4f}\")\n",
        "\n",
        "results_l2_raw = evaluate_model(\n",
        "    lr_l2_raw,\n",
        "    raw_processed['X_test'],\n",
        "    raw_processed['y_test'],\n",
        "    model_name='Logistic Regression (L2/Ridge)',\n",
        "    feature_type='raw',\n",
        "    label_encoder=raw_processed['label_encoder']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# L2 Logistic Regression - Engineered Features\n",
        "print(\"Training L2 Logistic Regression on ENGINEERED features with CV...\")\n",
        "\n",
        "lr_l2_eng = LogisticRegressionCV(\n",
        "    penalty='l2',\n",
        "    Cs=10,\n",
        "    cv=5,\n",
        "    scoring='f1_macro',\n",
        "    solver='lbfgs',\n",
        "    max_iter=1000,\n",
        "    class_weight='balanced',\n",
        "    random_state=RANDOM_STATE,\n",
        "    multi_class='multinomial',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lr_l2_eng.fit(eng_processed['X_train'], eng_processed['y_train'])\n",
        "\n",
        "print(f\"Best C: {lr_l2_eng.C_[0]:.4f}\")\n",
        "\n",
        "results_l2_eng = evaluate_model(\n",
        "    lr_l2_eng,\n",
        "    eng_processed['X_test'],\n",
        "    eng_processed['y_test'],\n",
        "    model_name='Logistic Regression (L2/Ridge)',\n",
        "    feature_type='engineered',\n",
        "    label_encoder=eng_processed['label_encoder']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Results Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile all results\n",
        "all_results = [\n",
        "    results_standard_raw,\n",
        "    results_standard_eng,\n",
        "    results_l1_raw,\n",
        "    results_l1_eng,\n",
        "    results_l2_raw,\n",
        "    results_l2_eng\n",
        "]\n",
        "\n",
        "# Create summary DataFrame\n",
        "summary_df = pd.DataFrame([\n",
        "    {\n",
        "        'Model': r['model_name'],\n",
        "        'Features': r['feature_type'],\n",
        "        'Accuracy': r['accuracy'],\n",
        "        'Balanced Acc': r['balanced_accuracy'],\n",
        "        'F1 (Macro)': r['f1_macro'],\n",
        "        'ROC-AUC': r['roc_auc']\n",
        "    }\n",
        "    for r in all_results\n",
        "])\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"LOGISTIC REGRESSION RESULTS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(summary_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Prepare data for plotting\n",
        "models = ['Standard', 'L1 (Lasso)', 'L2 (Ridge)']\n",
        "raw_f1 = [results_standard_raw['f1_macro'], results_l1_raw['f1_macro'], results_l2_raw['f1_macro']]\n",
        "eng_f1 = [results_standard_eng['f1_macro'], results_l1_eng['f1_macro'], results_l2_eng['f1_macro']]\n",
        "\n",
        "x = np.arange(len(models))\n",
        "width = 0.35\n",
        "\n",
        "# F1 Score comparison\n",
        "bars1 = axes[0].bar(x - width/2, raw_f1, width, label='Raw (PCA)', color='steelblue')\n",
        "bars2 = axes[0].bar(x + width/2, eng_f1, width, label='Engineered', color='coral')\n",
        "\n",
        "axes[0].set_ylabel('Macro F1 Score', fontsize=12)\n",
        "axes[0].set_title('Logistic Regression: F1 Score Comparison', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(models)\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "axes[0].set_ylim(0, 1)\n",
        "\n",
        "# Add value labels\n",
        "for bar in list(bars1) + list(bars2):\n",
        "    height = bar.get_height()\n",
        "    axes[0].annotate(f'{height:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
        "                     xytext=(0, 3), textcoords='offset points', ha='center', fontsize=9)\n",
        "\n",
        "# Balanced Accuracy comparison\n",
        "raw_ba = [results_standard_raw['balanced_accuracy'], results_l1_raw['balanced_accuracy'], results_l2_raw['balanced_accuracy']]\n",
        "eng_ba = [results_standard_eng['balanced_accuracy'], results_l1_eng['balanced_accuracy'], results_l2_eng['balanced_accuracy']]\n",
        "\n",
        "bars3 = axes[1].bar(x - width/2, raw_ba, width, label='Raw (PCA)', color='steelblue')\n",
        "bars4 = axes[1].bar(x + width/2, eng_ba, width, label='Engineered', color='coral')\n",
        "\n",
        "axes[1].set_ylabel('Balanced Accuracy', fontsize=12)\n",
        "axes[1].set_title('Logistic Regression: Balanced Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xticks(x)\n",
        "axes[1].set_xticklabels(models)\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "axes[1].set_ylim(0, 1)\n",
        "\n",
        "for bar in list(bars3) + list(bars4):\n",
        "    height = bar.get_height()\n",
        "    axes[1].annotate(f'{height:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
        "                     xytext=(0, 3), textcoords='offset points', ha='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results for final comparison\n",
        "save_results(all_results, 'logistic_regression')\n",
        "print(\"\\nResults saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Key Observations\n",
        "\n",
        "### Regularization Effects\n",
        "- **Standard (no regularization)**: May overfit, especially with high-dimensional data\n",
        "- **L1 (Lasso)**: Performs feature selection by zeroing out irrelevant coefficients\n",
        "- **L2 (Ridge)**: Shrinks all coefficients, often better for prediction\n",
        "\n",
        "### Feature Types\n",
        "- **Raw (PCA)**: Uses principal components from 4096 pixel values\n",
        "- **Engineered**: Uses 38 domain-specific features (edges, spatial, texture, etc.)\n",
        "\n",
        "### Class Imbalance Handling\n",
        "- Used `class_weight='balanced'` to account for ~74% forward, ~16% left, ~9% right\n",
        "- Evaluated with Macro F1 and Balanced Accuracy (not just accuracy)\n",
        "\n",
        "### Next Steps\n",
        "- Compare with non-linear models (kNN, trees, SVM with kernels)\n",
        "- Final model comparison in `10_model_comparison.ipynb`\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
